{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Autoencoder\nAutoencoders are used to learn efficient data codings in an unsupervised manner. The aim is to learn a representation (encoding) for a set of data, typically for the purpose of dimentionality reduction. The concept has become more widely used for generative models of data. Some of most powerful algorithms recently have involved sparse autoencoders stacked inside of deep neural networks.\n\nWe will try to create following autoencoders:\n- a simple autoencoder based on a fully connected layer\n- a sparse autoencoder\n- a deep fully-connected autoencoder\n- a deep convolutional autoencoder\n- an image denoising model\n- a sequence-to-sequence autoencoder\n- a variational autoenoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true}},{"cell_type":"markdown","source":"Autoencoders are data compression algorithms which are data-specific, lossy and learned automatically from examples. The compression and depcompression functions are implemented with neural networks.\n- Data specific: They will only be able to compress data similar to what they have been trained on. Unlike normal compression algorithms, they are not very generic about the data they hold. For example, an autoencoder trained on pictures of faces would do a poor job of compressing pictures of trees because the features it learned are face-specific.\n- Lossy: The decompressed outputs will be degraded compared to original inputs\n- Auto learned: It's easy to train specialized instances of the algorithm that will perform well on a specific type of input. It doesn't require new engineering, just appropriate training data\n\nWe need 3 things to build autoencodere: an encoding function, a decoding function and a distance function between the amount of information loss between the compressed representation of data and the decompressed representation (loss function).\n\n**Are they good at data compression?**\nNot really. The fact that they are are data-specific makes the generally impractival for real-world data compression problems. Making them genreal requires a lot of training data. Future advances might change this.\n\n**What are they good for?**\nData denoising and dimensionality reduction for data visualization. With appropriate dimensionality and sparsity constraints, autoencoders can learn data projections that are more interesting than PCA or other basic techniques.\n\n**What's the big deal with autoencoders?**\nAbsolutely fascinating for newcomers. They have long beein throught to be a potential avenue for the learning of useful representations without the need for labels. But since they are self-supervised, it's not a true unsupervised learning technique. ","metadata":{"_uuid":"2b7bf4f9be4c53b593d41abadbc2325f4f776ecf"}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-11-14T11:01:14.523953Z","iopub.execute_input":"2022-11-14T11:01:14.524243Z","iopub.status.idle":"2022-11-14T11:01:16.730756Z","shell.execute_reply.started":"2022-11-14T11:01:14.524172Z","shell.execute_reply":"2022-11-14T11:01:16.730052Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_data(path):\n    with np.load(path) as f:\n        x_train, y_train = f['x_train'], f['y_train']\n        x_test, y_test = f['x_test'], f['y_test']\n        return (x_train, y_train), (x_test, y_test)","metadata":{"_uuid":"7a9b9c36a12ae90bc632236dc43819652fbb0567","execution":{"iopub.status.busy":"2022-11-14T11:01:16.731579Z","iopub.execute_input":"2022-11-14T11:01:16.731830Z","iopub.status.idle":"2022-11-14T11:01:16.738849Z","shell.execute_reply.started":"2022-11-14T11:01:16.731788Z","shell.execute_reply":"2022-11-14T11:01:16.737528Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# we will start simple with a single fully-connected neural layer as encoder and decoder\n# this is the siez of our encoded representations\nENCODING_DIM = 32\n\n# input placeholder\ninput_img = tf.keras.layers.Input(shape=(784,))\n\n# this is the encoded representation of the input\nencoded = tf.keras.layers.Dense(ENCODING_DIM, activation='relu')(input_img)\n\n# this is the loss reconstruction of the input\ndecoded = tf.keras.layers.Dense(784, activation='sigmoid')(encoded)\n\n# this model maps an input to its recommendation\nautoencoder = tf.keras.models.Model(input_img, decoded)","metadata":{"_uuid":"6349e4954e84e598875d7ebf0da514ea33a5cf07","execution":{"iopub.status.busy":"2022-11-14T11:01:16.740044Z","iopub.execute_input":"2022-11-14T11:01:16.740523Z","iopub.status.idle":"2022-11-14T11:01:16.794086Z","shell.execute_reply.started":"2022-11-14T11:01:16.740474Z","shell.execute_reply":"2022-11-14T11:01:16.793506Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# let's also create a seprate encoder model\n# this mode maps an input to its encoded representation\nencoder = tf.keras.models.Model(input_img, encoded)","metadata":{"_uuid":"0ed0ba68f0901d990696c2c99d8ae79573062903","execution":{"iopub.status.busy":"2022-11-14T11:01:16.796481Z","iopub.execute_input":"2022-11-14T11:01:16.796772Z","iopub.status.idle":"2022-11-14T11:01:16.802533Z","shell.execute_reply.started":"2022-11-14T11:01:16.796727Z","shell.execute_reply":"2022-11-14T11:01:16.801941Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# as well as decoder model\n# create a placeholder for an encoded (32-dimensional) input\nencoded_input = tf.keras.layers.Input(shape=(ENCODING_DIM,))\n\n# retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n\n# create the decoder model\ndecoder = tf.keras.models.Model(encoded_input, decoder_layer(encoded_input))","metadata":{"_uuid":"51765643141c3d75a230aa546987ce1056c045e1","execution":{"iopub.status.busy":"2022-11-14T11:01:16.805200Z","iopub.execute_input":"2022-11-14T11:01:16.805421Z","iopub.status.idle":"2022-11-14T11:01:16.816626Z","shell.execute_reply.started":"2022-11-14T11:01:16.805381Z","shell.execute_reply":"2022-11-14T11:01:16.816025Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Now let's train our autoencoder to reconstruct MNIST digits\n# first we will configure our model to use a per-pixel binary crossentropy loss, and the Adadelta optimizer\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')","metadata":{"_uuid":"1ef1d7cb58713f533adb07c9f6ea95977ed44b2c","execution":{"iopub.status.busy":"2022-11-14T11:01:16.819174Z","iopub.execute_input":"2022-11-14T11:01:16.819386Z","iopub.status.idle":"2022-11-14T11:01:16.910233Z","shell.execute_reply.started":"2022-11-14T11:01:16.819346Z","shell.execute_reply":"2022-11-14T11:01:16.909629Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# let's prepare our input data. We are using MNIST digits and we are disregrading the labels (since we are only interested in encoding/decoding the input images)\n# load the data\n(x_train, _), (x_test, _) = load_data('../input/mnist.npz')","metadata":{"_uuid":"f186a9ad106a788fa9f3d3bb9d0120fecaf280d2","execution":{"iopub.status.busy":"2022-11-14T11:01:16.913058Z","iopub.execute_input":"2022-11-14T11:01:16.913302Z","iopub.status.idle":"2022-11-14T11:01:17.509664Z","shell.execute_reply.started":"2022-11-14T11:01:16.913236Z","shell.execute_reply":"2022-11-14T11:01:17.509012Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"x_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\nx_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nx_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\nprint(x_train.shape)\nprint(x_test.shape)","metadata":{"_uuid":"d130b8504a6288baea58220865a66451d976160e","execution":{"iopub.status.busy":"2022-11-14T11:01:17.510803Z","iopub.execute_input":"2022-11-14T11:01:17.511087Z","iopub.status.idle":"2022-11-14T11:01:17.747498Z","shell.execute_reply.started":"2022-11-14T11:01:17.511043Z","shell.execute_reply":"2022-11-14T11:01:17.746776Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(60000, 784)\n(10000, 784)\n","output_type":"stream"}]},{"cell_type":"code","source":"# now let's train our autoencoder for 50 epochs\nautoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test))","metadata":{"_uuid":"6421f91efca129a800ecc924b9785ac9877a90d5","_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-11-14T11:01:17.751201Z","iopub.execute_input":"2022-11-14T11:01:17.753069Z","iopub.status.idle":"2022-11-14T11:02:09.740197Z","shell.execute_reply.started":"2022-11-14T11:01:17.753014Z","shell.execute_reply":"2022-11-14T11:02:09.739539Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Train on 60000 samples, validate on 10000 samples\nEpoch 1/50\n60000/60000 [==============================] - 7s 120us/step - loss: 0.3607 - val_loss: 0.2716\nEpoch 2/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2648 - val_loss: 0.2546\nEpoch 3/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.2445 - val_loss: 0.2322\nEpoch 4/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.2243 - val_loss: 0.2142\nEpoch 5/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2090 - val_loss: 0.2012\nEpoch 6/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1980 - val_loss: 0.1919\nEpoch 7/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1898 - val_loss: 0.1846\nEpoch 8/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1830 - val_loss: 0.1785\nEpoch 9/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1772 - val_loss: 0.1730\nEpoch 10/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1721 - val_loss: 0.1683\nEpoch 11/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1675 - val_loss: 0.1638\nEpoch 12/50\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1631 - val_loss: 0.1596\nEpoch 13/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1591 - val_loss: 0.1557\nEpoch 14/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1553 - val_loss: 0.1522\nEpoch 15/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1519 - val_loss: 0.1487\nEpoch 16/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1487 - val_loss: 0.1457\nEpoch 17/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1458 - val_loss: 0.1428\nEpoch 18/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1431 - val_loss: 0.1402\nEpoch 19/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1405 - val_loss: 0.1378\nEpoch 20/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1382 - val_loss: 0.1355\nEpoch 21/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1360 - val_loss: 0.1333\nEpoch 22/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1339 - val_loss: 0.1313\nEpoch 23/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1319 - val_loss: 0.1293\nEpoch 24/50\n60000/60000 [==============================] - 1s 18us/step - loss: 0.1300 - val_loss: 0.1275\nEpoch 25/50\n60000/60000 [==============================] - 1s 16us/step - loss: 0.1282 - val_loss: 0.1257\nEpoch 26/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1264 - val_loss: 0.1240\nEpoch 27/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1248 - val_loss: 0.1224\nEpoch 28/50\n60000/60000 [==============================] - 1s 23us/step - loss: 0.1232 - val_loss: 0.1209\nEpoch 29/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1217 - val_loss: 0.1195\nEpoch 30/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1203 - val_loss: 0.1181\nEpoch 31/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1190 - val_loss: 0.1168\nEpoch 32/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1178 - val_loss: 0.1156\nEpoch 33/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1167 - val_loss: 0.1145\nEpoch 34/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1156 - val_loss: 0.1136\nEpoch 35/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1147 - val_loss: 0.1126\nEpoch 36/50\n60000/60000 [==============================] - 1s 20us/step - loss: 0.1138 - val_loss: 0.1117\nEpoch 37/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1129 - val_loss: 0.1109\nEpoch 38/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1122 - val_loss: 0.1102\nEpoch 39/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1115 - val_loss: 0.1095\nEpoch 40/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1108 - val_loss: 0.1089\nEpoch 41/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1103 - val_loss: 0.1084\nEpoch 42/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1097 - val_loss: 0.1078\nEpoch 43/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1092 - val_loss: 0.1074\nEpoch 44/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1087 - val_loss: 0.1069\nEpoch 45/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1083 - val_loss: 0.1065\nEpoch 46/50\n60000/60000 [==============================] - 1s 14us/step - loss: 0.1079 - val_loss: 0.1061\nEpoch 47/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1075 - val_loss: 0.1057\nEpoch 48/50\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1072 - val_loss: 0.1054\nEpoch 49/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1069 - val_loss: 0.1051\nEpoch 50/50\n60000/60000 [==============================] - 1s 15us/step - loss: 0.1066 - val_loss: 0.1048\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f486a03b588>"},"metadata":{}}]},{"cell_type":"code","source":"# after 50 epochs the autoencoder seems to reach a stable train/test loss value of about 0.11. We can try to visualize the reconstructed inputs and the encoded representations. We will be using Matplotlib\n# encode and decode some digits\n# note that we take them from the \"test\" set\nencoded_imgs = encoder.predict(x_test)\ndecoded_imgs = decoder.predict(encoded_imgs)","metadata":{"_uuid":"116d321f464d9206b6eb350f2865359ae4dbd3d3","execution":{"iopub.status.busy":"2022-11-14T11:02:09.741303Z","iopub.execute_input":"2022-11-14T11:02:09.741564Z","iopub.status.idle":"2022-11-14T11:02:10.260459Z","shell.execute_reply.started":"2022-11-14T11:02:09.741514Z","shell.execute_reply":"2022-11-14T11:02:10.259796Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# now using Matplotlib to plot the images\nn = 10 # how many images we will display\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\nplt.show()","metadata":{"_uuid":"14858a1264fd5219566026623d8f06f98a759ca6","execution":{"iopub.status.busy":"2022-11-14T11:02:10.263567Z","iopub.execute_input":"2022-11-14T11:02:10.263856Z","iopub.status.idle":"2022-11-14T11:02:10.947272Z","shell.execute_reply.started":"2022-11-14T11:02:10.263807Z","shell.execute_reply":"2022-11-14T11:02:10.946577Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<matplotlib.figure.Figure at 0x7f4866a49940>","image/png":"iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlzvZjFaYq+sAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"markdown","source":"Adding a sparsity constraint on the encoded representations\nThe representations were only constrained by the size of the hidden layer (32). In such a situation, the hidden layer is learning an approximation of PCA. But another way to constain the representation to be compact is to add a sparsity constraint on the activity of the hiddne representations, so fewer units would \"fire\" at a given time. We can do this by adding `activity_regularizer` to our `Dense` layer.","metadata":{"_uuid":"cedde6daf149cc161cc17ceb935c8f8c24066887","trusted":true}},{"cell_type":"code","source":"ENCODING_DIM = 32\n\ninput_img = tf.keras.layers.Input(shape=(784,))\n\n# add a dense layer with L1 activity regularizer\nencoded = tf.keras.layers.Dense(ENCODING_DIM, activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-5))(input_img)\ndecoded = tf.keras.layers.Dense(784, activation='sigmoid')(encoded)\nautoencoder = tf.keras.models.Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n\n# now let's train this for 100 epochs (with added regularization, the model is less likely to overfit and can be trained longer). The model ends with a train loss of 0.11 and test loss of 0.10. The difference is mostly due to the regularization term being added to the loss during training\nautoencoder.fit(x_train, x_train, epochs=100, batch_size=256, shuffle=True, validation_data=(x_test, x_test))","metadata":{"_uuid":"d41c232133bd0be91441df9b69d7a516caa9d036","_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-11-14T11:02:10.948536Z","iopub.execute_input":"2022-11-14T11:02:10.949072Z","iopub.status.idle":"2022-11-14T11:03:44.478632Z","shell.execute_reply.started":"2022-11-14T11:02:10.949019Z","shell.execute_reply":"2022-11-14T11:03:44.477578Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Train on 60000 samples, validate on 10000 samples\nEpoch 1/100\n60000/60000 [==============================] - 1s 20us/step - loss: 0.6728 - val_loss: 0.6485\nEpoch 2/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.6284 - val_loss: 0.6090\nEpoch 3/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.5916 - val_loss: 0.5749\nEpoch 4/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.5598 - val_loss: 0.5454\nEpoch 5/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.5323 - val_loss: 0.5198\nEpoch 6/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.5084 - val_loss: 0.4975\nEpoch 7/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.4875 - val_loss: 0.4780\nEpoch 8/100\n60000/60000 [==============================] - 1s 18us/step - loss: 0.4692 - val_loss: 0.4609\nEpoch 9/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.4531 - val_loss: 0.4457\nEpoch 10/100\n60000/60000 [==============================] - 1s 24us/step - loss: 0.4388 - val_loss: 0.4324\nEpoch 11/100\n60000/60000 [==============================] - 1s 16us/step - loss: 0.4262 - val_loss: 0.4205\nEpoch 12/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.4150 - val_loss: 0.4098\nEpoch 13/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.4049 - val_loss: 0.4003\nEpoch 14/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3959 - val_loss: 0.3918\nEpoch 15/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3877 - val_loss: 0.3840\nEpoch 16/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3804 - val_loss: 0.3771\nEpoch 17/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3737 - val_loss: 0.3707\nEpoch 18/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3676 - val_loss: 0.3649\nEpoch 19/100\n60000/60000 [==============================] - 1s 16us/step - loss: 0.3621 - val_loss: 0.3596\nEpoch 20/100\n60000/60000 [==============================] - 1s 17us/step - loss: 0.3570 - val_loss: 0.3548\nEpoch 21/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3524 - val_loss: 0.3503\nEpoch 22/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3481 - val_loss: 0.3463\nEpoch 23/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3442 - val_loss: 0.3425\nEpoch 24/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3406 - val_loss: 0.3390\nEpoch 25/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3372 - val_loss: 0.3357\nEpoch 26/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3341 - val_loss: 0.3327\nEpoch 27/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3312 - val_loss: 0.3299\nEpoch 28/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3285 - val_loss: 0.3273\nEpoch 29/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3259 - val_loss: 0.3249\nEpoch 30/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3236 - val_loss: 0.3226\nEpoch 31/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3213 - val_loss: 0.3204\nEpoch 32/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.3193 - val_loss: 0.3184\nEpoch 33/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3173 - val_loss: 0.3165\nEpoch 34/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3155 - val_loss: 0.3147\nEpoch 35/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3138 - val_loss: 0.3131\nEpoch 36/100\n60000/60000 [==============================] - 1s 14us/step - loss: 0.3121 - val_loss: 0.3115\nEpoch 37/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3106 - val_loss: 0.3100\nEpoch 38/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3091 - val_loss: 0.3085\nEpoch 39/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3077 - val_loss: 0.3072\nEpoch 40/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3064 - val_loss: 0.3059\nEpoch 41/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3052 - val_loss: 0.3047\nEpoch 42/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3040 - val_loss: 0.3035\nEpoch 43/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3029 - val_loss: 0.3024\nEpoch 44/100\n60000/60000 [==============================] - 2s 29us/step - loss: 0.3018 - val_loss: 0.3014\nEpoch 45/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.3008 - val_loss: 0.3004\nEpoch 46/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2998 - val_loss: 0.2994\nEpoch 47/100\n60000/60000 [==============================] - 1s 14us/step - loss: 0.2989 - val_loss: 0.2985\nEpoch 48/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2980 - val_loss: 0.2976\nEpoch 49/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2971 - val_loss: 0.2968\nEpoch 50/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2963 - val_loss: 0.2960\nEpoch 51/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2955 - val_loss: 0.2952\nEpoch 52/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2948 - val_loss: 0.2945\nEpoch 53/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2941 - val_loss: 0.2938\nEpoch 54/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2934 - val_loss: 0.2931\nEpoch 55/100\n60000/60000 [==============================] - 1s 18us/step - loss: 0.2927 - val_loss: 0.2925\nEpoch 56/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2921 - val_loss: 0.2918\nEpoch 57/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2915 - val_loss: 0.2912\nEpoch 58/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2909 - val_loss: 0.2906\nEpoch 59/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2903 - val_loss: 0.2901\nEpoch 60/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2898 - val_loss: 0.2895\nEpoch 61/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2892 - val_loss: 0.2890\nEpoch 62/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2887 - val_loss: 0.2885\nEpoch 63/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2882 - val_loss: 0.2880\nEpoch 64/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2877 - val_loss: 0.2875\nEpoch 65/100\n60000/60000 [==============================] - 1s 16us/step - loss: 0.2873 - val_loss: 0.2871\nEpoch 66/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2868 - val_loss: 0.2867\nEpoch 67/100\n60000/60000 [==============================] - 1s 17us/step - loss: 0.2864 - val_loss: 0.2862\nEpoch 68/100\n60000/60000 [==============================] - 1s 16us/step - loss: 0.2860 - val_loss: 0.2858\nEpoch 69/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2856 - val_loss: 0.2854\nEpoch 70/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2852 - val_loss: 0.2850\nEpoch 71/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2848 - val_loss: 0.2846\nEpoch 72/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2844 - val_loss: 0.2843\nEpoch 73/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2841 - val_loss: 0.2839\nEpoch 74/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2837 - val_loss: 0.2836\nEpoch 75/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2834 - val_loss: 0.2832\nEpoch 76/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2831 - val_loss: 0.2829\nEpoch 77/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2828 - val_loss: 0.2826\nEpoch 78/100\n60000/60000 [==============================] - 1s 25us/step - loss: 0.2825 - val_loss: 0.2823\nEpoch 79/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.2822 - val_loss: 0.2820\nEpoch 80/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2819 - val_loss: 0.2817\nEpoch 81/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2816 - val_loss: 0.2814\nEpoch 82/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2813 - val_loss: 0.2812\nEpoch 83/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2810 - val_loss: 0.2809\nEpoch 84/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2808 - val_loss: 0.2806\nEpoch 85/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2805 - val_loss: 0.2804\nEpoch 86/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2803 - val_loss: 0.2801\nEpoch 87/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2800 - val_loss: 0.2799\nEpoch 88/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2798 - val_loss: 0.2796\nEpoch 89/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2796 - val_loss: 0.2794\nEpoch 90/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2793 - val_loss: 0.2792\nEpoch 91/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.2791 - val_loss: 0.2790\nEpoch 92/100\n60000/60000 [==============================] - 1s 16us/step - loss: 0.2789 - val_loss: 0.2788\nEpoch 93/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2787 - val_loss: 0.2785\nEpoch 94/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2785 - val_loss: 0.2783\nEpoch 95/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2783 - val_loss: 0.2781\nEpoch 96/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2781 - val_loss: 0.2780\nEpoch 97/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2779 - val_loss: 0.2778\nEpoch 98/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2777 - val_loss: 0.2776\nEpoch 99/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2775 - val_loss: 0.2774\nEpoch 100/100\n60000/60000 [==============================] - 1s 15us/step - loss: 0.2774 - val_loss: 0.2772\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f48402e8e80>"},"metadata":{}}]},{"cell_type":"code","source":"# now using Matplotlib to plot the images\nn = 10 # how many images we will display\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\nplt.show()","metadata":{"_uuid":"dab629feb565109e32866e2cf1c01bb07569e9cf","execution":{"iopub.status.busy":"2022-11-14T11:03:44.479861Z","iopub.execute_input":"2022-11-14T11:03:44.480127Z","iopub.status.idle":"2022-11-14T11:03:45.155464Z","shell.execute_reply.started":"2022-11-14T11:03:44.480077Z","shell.execute_reply":"2022-11-14T11:03:45.154753Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<matplotlib.figure.Figure at 0x7f4806297898>","image/png":"iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlzvZjFaYq+sAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"markdown","source":"The images look pretty similar to the previous model, the only significant difference being the sparsity of the encoded representations. `encoded_imgs.mean()` yields a value of 3.33 over 10,000 test images. whereas with previous model the same quantity was 7.30. So our new model yields encoded representations that are twice sparser.\n\n**Deep autoencoder**\nWe do not have to limit ourselves to a single layer as encoder or decoder, we could instead use a stack of layers.","metadata":{"_uuid":"c75540b69ead49ba2170aafd1c8cc557125845ed","trusted":true}},{"cell_type":"code","source":"input_img = tf.keras.layers.Input(shape=(784,))\nencoded = tf.keras.layers.Dense(128, activation='relu')(input_img)\nencoded = tf.keras.layers.Dense(64, activation='relu')(encoded)\nencoded = tf.keras.layers.Dense(32, activation='relu')(encoded)\n\ndecoded = tf.keras.layers.Dense(64, activation='relu')(encoded)\ndecoded = tf.keras.layers.Dense(128, activation='relu')(decoded)\ndecoded = tf.keras.layers.Dense(784, activation='sigmoid')(decoded)","metadata":{"_uuid":"174cf23abc172e65c274ff4df5c7c557d7a31ced","execution":{"iopub.status.busy":"2022-11-14T11:03:45.156499Z","iopub.execute_input":"2022-11-14T11:03:45.156911Z","iopub.status.idle":"2022-11-14T11:03:45.236087Z","shell.execute_reply.started":"2022-11-14T11:03:45.156852Z","shell.execute_reply":"2022-11-14T11:03:45.235466Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# let's try this\nautoencoder = tf.keras.models.Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n\nautoencoder.fit(x_train, x_train, epochs=100, batch_size=256, shuffle=True, validation_data=(x_test, x_test))","metadata":{"_uuid":"996a5443874301ea1ae2e5acf16288f75a053b53","_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-11-14T11:03:45.237330Z","iopub.execute_input":"2022-11-14T11:03:45.237672Z","iopub.status.idle":"2022-11-14T11:05:46.609675Z","shell.execute_reply.started":"2022-11-14T11:03:45.237589Z","shell.execute_reply":"2022-11-14T11:05:46.608823Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Train on 60000 samples, validate on 10000 samples\nEpoch 1/100\n60000/60000 [==============================] - 2s 32us/step - loss: 0.3419 - val_loss: 0.2629\nEpoch 2/100\n60000/60000 [==============================] - 1s 20us/step - loss: 0.2577 - val_loss: 0.2526\nEpoch 3/100\n60000/60000 [==============================] - 1s 20us/step - loss: 0.2408 - val_loss: 0.2281\nEpoch 4/100\n60000/60000 [==============================] - 1s 20us/step - loss: 0.2175 - val_loss: 0.2102\nEpoch 5/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.2069 - val_loss: 0.2016\nEpoch 6/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1967 - val_loss: 0.1889\nEpoch 7/100\n60000/60000 [==============================] - 2s 27us/step - loss: 0.1853 - val_loss: 0.1786\nEpoch 8/100\n60000/60000 [==============================] - 1s 20us/step - loss: 0.1770 - val_loss: 0.1715\nEpoch 9/100\n60000/60000 [==============================] - 1s 22us/step - loss: 0.1709 - val_loss: 0.1680\nEpoch 10/100\n60000/60000 [==============================] - 1s 21us/step - loss: 0.1662 - val_loss: 0.1651\nEpoch 11/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1615 - val_loss: 0.1572\nEpoch 12/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1569 - val_loss: 0.1550\nEpoch 13/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1535 - val_loss: 0.1487\nEpoch 14/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1506 - val_loss: 0.1472\nEpoch 15/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1481 - val_loss: 0.1471\nEpoch 16/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1459 - val_loss: 0.1438\nEpoch 17/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1438 - val_loss: 0.1401\nEpoch 18/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1417 - val_loss: 0.1393\nEpoch 19/100\n60000/60000 [==============================] - 1s 24us/step - loss: 0.1400 - val_loss: 0.1388\nEpoch 20/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1383 - val_loss: 0.1351\nEpoch 21/100\n60000/60000 [==============================] - 1s 20us/step - loss: 0.1369 - val_loss: 0.1355\nEpoch 22/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1354 - val_loss: 0.1340\nEpoch 23/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1341 - val_loss: 0.1318\nEpoch 24/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1330 - val_loss: 0.1303\nEpoch 25/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1314 - val_loss: 0.1302\nEpoch 26/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1304 - val_loss: 0.1283\nEpoch 27/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1291 - val_loss: 0.1266\nEpoch 28/100\n60000/60000 [==============================] - 1s 23us/step - loss: 0.1280 - val_loss: 0.1263\nEpoch 29/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1268 - val_loss: 0.1266\nEpoch 30/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1259 - val_loss: 0.1241\nEpoch 31/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1251 - val_loss: 0.1228\nEpoch 32/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1242 - val_loss: 0.1221\nEpoch 33/100\n60000/60000 [==============================] - 1s 24us/step - loss: 0.1234 - val_loss: 0.1208\nEpoch 34/100\n60000/60000 [==============================] - 1s 23us/step - loss: 0.1227 - val_loss: 0.1210\nEpoch 35/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1220 - val_loss: 0.1205\nEpoch 36/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1212 - val_loss: 0.1193\nEpoch 37/100\n60000/60000 [==============================] - 1s 24us/step - loss: 0.1205 - val_loss: 0.1184\nEpoch 38/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1198 - val_loss: 0.1184\nEpoch 39/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1188 - val_loss: 0.1168\nEpoch 40/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1183 - val_loss: 0.1168\nEpoch 41/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1175 - val_loss: 0.1164\nEpoch 42/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1169 - val_loss: 0.1153\nEpoch 43/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1163 - val_loss: 0.1145\nEpoch 44/100\n60000/60000 [==============================] - 1s 20us/step - loss: 0.1156 - val_loss: 0.1140\nEpoch 45/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1150 - val_loss: 0.1140\nEpoch 46/100\n60000/60000 [==============================] - 1s 23us/step - loss: 0.1144 - val_loss: 0.1122\nEpoch 47/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1139 - val_loss: 0.1129\nEpoch 48/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1133 - val_loss: 0.1115\nEpoch 49/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1127 - val_loss: 0.1109\nEpoch 50/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1123 - val_loss: 0.1116\nEpoch 51/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1118 - val_loss: 0.1097\nEpoch 52/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1114 - val_loss: 0.1096\nEpoch 53/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1110 - val_loss: 0.1097\nEpoch 54/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1106 - val_loss: 0.1086\nEpoch 55/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1102 - val_loss: 0.1069\nEpoch 56/100\n60000/60000 [==============================] - 1s 24us/step - loss: 0.1098 - val_loss: 0.1102\nEpoch 57/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1096 - val_loss: 0.1085\nEpoch 58/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1092 - val_loss: 0.1068\nEpoch 59/100\n60000/60000 [==============================] - 1s 22us/step - loss: 0.1088 - val_loss: 0.1064\nEpoch 60/100\n60000/60000 [==============================] - 1s 25us/step - loss: 0.1085 - val_loss: 0.1074\nEpoch 61/100\n60000/60000 [==============================] - 1s 20us/step - loss: 0.1082 - val_loss: 0.1064\nEpoch 62/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1078 - val_loss: 0.1073\nEpoch 63/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1075 - val_loss: 0.1062\nEpoch 64/100\n60000/60000 [==============================] - 1s 22us/step - loss: 0.1072 - val_loss: 0.1082\nEpoch 65/100\n60000/60000 [==============================] - 1s 22us/step - loss: 0.1071 - val_loss: 0.1064\nEpoch 66/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1065 - val_loss: 0.1059\nEpoch 67/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1064 - val_loss: 0.1044\nEpoch 68/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1059 - val_loss: 0.1048\nEpoch 69/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1058 - val_loss: 0.1042\nEpoch 70/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1055 - val_loss: 0.1031\nEpoch 71/100\n60000/60000 [==============================] - 1s 20us/step - loss: 0.1051 - val_loss: 0.1050\nEpoch 72/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1050 - val_loss: 0.1056\nEpoch 73/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1047 - val_loss: 0.1031\nEpoch 74/100\n60000/60000 [==============================] - 1s 24us/step - loss: 0.1044 - val_loss: 0.1038\nEpoch 75/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1041 - val_loss: 0.1034\nEpoch 76/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1040 - val_loss: 0.1023\nEpoch 77/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1037 - val_loss: 0.1033\nEpoch 78/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1035 - val_loss: 0.1015\nEpoch 79/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1033 - val_loss: 0.1023\nEpoch 80/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1032 - val_loss: 0.1022\nEpoch 81/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1029 - val_loss: 0.1017\nEpoch 82/100\n60000/60000 [==============================] - 1s 20us/step - loss: 0.1028 - val_loss: 0.1019\nEpoch 83/100\n60000/60000 [==============================] - 1s 23us/step - loss: 0.1026 - val_loss: 0.1020\nEpoch 84/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1024 - val_loss: 0.1021\nEpoch 85/100\n60000/60000 [==============================] - 1s 22us/step - loss: 0.1023 - val_loss: 0.1013\nEpoch 86/100\n60000/60000 [==============================] - 2s 27us/step - loss: 0.1020 - val_loss: 0.1011\nEpoch 87/100\n60000/60000 [==============================] - 1s 20us/step - loss: 0.1019 - val_loss: 0.1005\nEpoch 88/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1019 - val_loss: 0.1002\nEpoch 89/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1014 - val_loss: 0.1026\nEpoch 90/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1015 - val_loss: 0.1006\nEpoch 91/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1012 - val_loss: 0.1007\nEpoch 92/100\n60000/60000 [==============================] - 1s 24us/step - loss: 0.1011 - val_loss: 0.0994\nEpoch 93/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1009 - val_loss: 0.1001\nEpoch 94/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1009 - val_loss: 0.0983\nEpoch 95/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1005 - val_loss: 0.0990\nEpoch 96/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1005 - val_loss: 0.0998\nEpoch 97/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1004 - val_loss: 0.0998\nEpoch 98/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1002 - val_loss: 0.0989\nEpoch 99/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1001 - val_loss: 0.0994\nEpoch 100/100\n60000/60000 [==============================] - 1s 19us/step - loss: 0.1000 - val_loss: 0.0986\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f4866a30c18>"},"metadata":{}}]},{"cell_type":"code","source":"# now using Matplotlib to plot the images\nn = 10 # how many images we will display\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\nplt.show()","metadata":{"_uuid":"b33d8f20b38e69a7202caeac158b11301de51490","execution":{"iopub.status.busy":"2022-11-14T11:05:46.611019Z","iopub.execute_input":"2022-11-14T11:05:46.611496Z","iopub.status.idle":"2022-11-14T11:05:47.274896Z","shell.execute_reply.started":"2022-11-14T11:05:46.611436Z","shell.execute_reply":"2022-11-14T11:05:47.274177Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<matplotlib.figure.Figure at 0x7f484252a0f0>","image/png":"iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlzvZjFaYq+sAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"markdown","source":"Convolutional autoencoder\n\nSince our inputs are images, it makes sense to use convolutional neural networks (CNNs) as encoders and decoders. In practical settings, autoencoders for images are always convolutional since they perform much better.\n\nThis encoder will consist in a stack of `Conv2D` and `MaxPooling2D` layers (for spatial down-sampling), while the decoder will consist in a stack of `Conv2D` and `UpSampling2D` layers.","metadata":{"_uuid":"2e312587cf9e63b216977e0ee6b67f9fd8a88e95"}},{"cell_type":"code","source":"input_img = tf.keras.layers.Input(shape=(28, 28, 1)) # adapt this if using `channels_first` image data format\n\nx = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\nx = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\nx = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n\n# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n\nx = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = tf.keras.layers.UpSampling2D((2, 2))(x)\nx = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = tf.keras.layers.UpSampling2D((2, 2))(x)\nx = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')(x)\nx = tf.keras.layers.UpSampling2D((2, 2))(x)\ndecoded = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = tf.keras.models.Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')","metadata":{"_uuid":"a1018831fdbbfb850efc7f37fcc58bc452d2e03b","execution":{"iopub.status.busy":"2022-11-14T11:05:47.276024Z","iopub.execute_input":"2022-11-14T11:05:47.276451Z","iopub.status.idle":"2022-11-14T11:05:47.525924Z","shell.execute_reply.started":"2022-11-14T11:05:47.276396Z","shell.execute_reply":"2022-11-14T11:05:47.524343Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# to train this model we will with original MNIST digits with shape (samples, 3, 28, 28) and we will just normalize pixel values between 0 and 1\n(x_train, _), (x_test, _) = load_data('../input/mnist.npz')\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\nx_test = np.reshape(x_test, (len(x_test), 28, 28, 1))","metadata":{"_uuid":"a6028dbec49a653296553602adbe64a3d31d6ed9","execution":{"iopub.status.busy":"2022-11-14T11:05:47.527069Z","iopub.execute_input":"2022-11-14T11:05:47.527467Z","iopub.status.idle":"2022-11-14T11:05:48.046825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.fit(x_train, x_train, epochs=50, batch_size=128, shuffle=True, validation_data=(x_test, x_test), callbacks=[tf.keras.callbacks.TensorBoard(log_dir='./tmp/autoencoder')])","metadata":{"_uuid":"485bb23ee67b2ead1f1ec454326a1cabc995eff1","_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-11-14T11:05:48.048134Z","iopub.execute_input":"2022-11-14T11:05:48.048406Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Train on 60000 samples, validate on 10000 samples\nEpoch 1/50\n60000/60000 [==============================] - 7s 111us/step - loss: 0.2181 - val_loss: 0.1750\nEpoch 2/50\n60000/60000 [==============================] - 4s 67us/step - loss: 0.1584 - val_loss: 0.1482\nEpoch 3/50\n60000/60000 [==============================] - 4s 69us/step - loss: 0.1447 - val_loss: 0.1397\nEpoch 4/50\n60000/60000 [==============================] - 4s 61us/step - loss: 0.1370 - val_loss: 0.1309\nEpoch 5/50\n60000/60000 [==============================] - 4s 65us/step - loss: 0.1313 - val_loss: 0.1280\nEpoch 6/50\n60000/60000 [==============================] - 4s 62us/step - loss: 0.1266 - val_loss: 0.1207\nEpoch 7/50\n60000/60000 [==============================] - 4s 61us/step - loss: 0.1228 - val_loss: 0.1209\nEpoch 8/50\n60000/60000 [==============================] - 4s 66us/step - loss: 0.1201 - val_loss: 0.1148\nEpoch 9/50\n60000/60000 [==============================] - 4s 61us/step - loss: 0.1179 - val_loss: 0.1171\nEpoch 10/50\n60000/60000 [==============================] - 4s 62us/step - loss: 0.1164 - val_loss: 0.1162\nEpoch 11/50\n60000/60000 [==============================] - 5s 77us/step - loss: 0.1151 - val_loss: 0.1106\nEpoch 12/50\n60000/60000 [==============================] - 4s 61us/step - loss: 0.1138 - val_loss: 0.1094\nEpoch 13/50\n60000/60000 [==============================] - 4s 62us/step - loss: 0.1128 - val_loss: 0.1115\nEpoch 14/50\n60000/60000 [==============================] - 4s 65us/step - loss: 0.1121 - val_loss: 0.1105\nEpoch 15/50\n60000/60000 [==============================] - 4s 61us/step - loss: 0.1113 - val_loss: 0.1070\nEpoch 16/50\n60000/60000 [==============================] - 4s 62us/step - loss: 0.1100 - val_loss: 0.1060\nEpoch 17/50\n60000/60000 [==============================] - 4s 66us/step - loss: 0.1092 - val_loss: 0.1109\nEpoch 18/50\n60000/60000 [==============================] - 4s 61us/step - loss: 0.1084 - val_loss: 0.1072\nEpoch 19/50\n60000/60000 [==============================] - 5s 76us/step - loss: 0.1078 - val_loss: 0.1061\nEpoch 20/50\n60000/60000 [==============================] - 4s 61us/step - loss: 0.1074 - val_loss: 0.1040\nEpoch 21/50\n 1920/60000 [..............................] - ETA: 3s - loss: 0.1070","output_type":"stream"}]},{"cell_type":"markdown","source":"The model converges to a loss of 0.098, significantly better than previous model which is in large part due to the higher entropic capacity of the encoded representations (128 vs 32 previously).","metadata":{"_uuid":"29103c9e23d1f1ba10874bb05dcd8e89c8075f1f"}},{"cell_type":"code","source":"decoded_imgs = autoencoder.predict(x_test)\n\nn = 10\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()\n","metadata":{"_uuid":"555579d1cb40a706f455307cd4feff5d506b9c40","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # we can also look at the 128-dimensional encoded representations. These representations are 8x4x4, so we reshape them to 4x32 in order to be able to display them as grayscale images\n# n = 10\n# plt.figure(figsize=(20, 8))\n# for i in range(n):\n#     ax = plt.subplot(1, n, i + 1)\n#     plt.imshow(encoded_imgs[i + 1].reshape(4, 4 * 8).T)\n#     plt.gray()\n#     ax.get_xaxis().set_visible(False)\n#     ax.get_yaxis().set_visible(False)\n# plt.show()","metadata":{"_uuid":"ae79608359a628aa2b8a351f580b12734e54b21b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Application to image denoising\n\nLet's put our convolutional autoencoder to work on an image denoising problem. We will train the autoencoder to map noisy digits images to clean digit images. We will generate synthetic noisy digits by applying a gaussian noise matrix and clip the images between 0 and 1.","metadata":{"_uuid":"eff13363f58882431933fc230ac7d7e2f7d631ad"}},{"cell_type":"code","source":"(x_train, _), (x_test, _) = load_data('../input/mnist.npz')\n\nx_train = x_train.astype('float32') / 255.\nx_test = x_test.astype('float32') / 255.\nx_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\nx_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n\nnoise_factor = 0.5\nx_train_noisy = x_train + noise_factor + np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\nx_test_noisy = x_test + noise_factor + np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n\nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)","metadata":{"_uuid":"f551217d3a192881b862c249158ecfadd375056e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# here's what the noisy digits look like\nn = 10\nplt.figure(figsize=(20, 2))\nfor i in range(n):\n    ax = plt.subplot(1, n, i + 1)\n    plt.imshow(x_test_noisy[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","metadata":{"_uuid":"0d66b7e2298faf79b252a993cbe3e8ac6a5ff359","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Can our autoencoder learn to recover the original digits. We will use a slightly different model with more filters per layer\ninput_img = tf.keras.layers.Input(shape=(28, 28, 1))\n\nx = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\nx = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\nx = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nencoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n\n# the representation is (7, 7, 32)\n\nx = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\nx = tf.keras.layers.UpSampling2D((2, 2))(x)\nx = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = tf.keras.layers.UpSampling2D((2, 2))(x)\ndecoded = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = tf.keras.models.Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')","metadata":{"_uuid":"50876255cff1014e168a486281dc589480f1e36a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# let's train for 100 epochs\nautoencoder.fit(x_train_noisy, x_train, epochs=100, batch_size=128, shuffle=True, validation_data=(x_test_noisy, x_test), callbacks=[tf.keras.callbacks.TensorBoard(log_dir='./tmp/tb', histogram_freq=0, write_graph=False)])","metadata":{"_uuid":"be79bebe3aecc00a3f9fdd8e2da0f650efcd60df","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see how it did\ndecoded_imgs = autoencoder.predict(x_test)\n\nn = 10\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test_noisy[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","metadata":{"_uuid":"fe992cc47326291b7f2b41ae0ddbbe4212908fd4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sequence-to-sequence autoencoder\n\nIf your inputs are sequences, rather than vectors of 2D images, then you may want your encoder and decoder to capture temporal structure, such as a LSTM. To build a LSTM-based autoencoder, first use a LSTM encoder to turn your input sequences into a single vecotr that contains information about the entire sequence, then repeat this vector n times (where n is the number of timesteps in the output sequence), and run a LSTM decoder to turn this constant sequence into the target sequence.\n\nFollowing is a code example which you can implement for your dataset.","metadata":{"_uuid":"a091f71a78e216c3ebed64bdb9f05cbeb14a108c"}},{"cell_type":"code","source":"# inputs = tf.keras.layers.Input(shape=(timesteps, input_dim))\n# encoded = tf.keras.layers.LSTM(latent_dim)(inputs)\n\n# decoded = tf.keras.layers.RepeatVector(timesteps)(encoded)\n# decoded = tf.keras.layers.LSTM(input_dmi, return_sequences=True)(decoded)\n\n# sequence_autoencoder = tf.keras.models.Model(inputs, decoded)\n# encoder = tf.keras.models.Model(inputs, encoded)","metadata":{"_uuid":"e329640ea1a99ee345f355405234f50d6be0796c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Variational Autoencoder (VAE)\n\nVariational autoencoders are a slightly more modern and interesting take on autoencoding. It's a type of autoencoder with added constraints on the encoded representations being learned. More precisely, it is an autoencoder that learns a latent variable model for its input data. So instead of letting your neural network learn an arbitrary function, you are learning the parameters of a probability distribution modeling your data. If you sample points from this distribution, you an generate new input data samples. VAE is a generative model.\n\n**How does it work?**\nFirst, an encoder network turns the input samples `x` into two parameters in a latent space, which we will note as `z_mean` and `z_log_sigma`. Then we randomly sample similar points `z` from the latent normal distribution that is assumed to generate the data, via `z = z_mean + exp(x_log_sigma) * epsilon`, where `epsilon` is a random normal tensor. Finally, a deocded network maps these latent space points back to the original input data.\n\nThe parameters of the model are trained via two loss functions: a reconstriction loss forcing the decoded samples to match the initial inputs (just like in our previous autoencoders), and the KL divergence between the learned latent distribution and the prior distribution, acting as a regulaization term. You could actually get rid of this latter term entirely, although it does help in learning well-formed latent spaces and reducing overfitting to the training data.","metadata":{"_uuid":"4576c65796c42ab9030409f21b13834b7e96b027"}},{"cell_type":"code","source":"# helper functions\n\n# reparameterization trick\n# instead of sampling from Q(z|X), sample eps = N(0,I)\n# z = z_mean + sqrt(var)*eps\ndef sampling(args):\n    z_mean, z_log_var = args\n    batch = tf.keras.backend.shape(z_mean)[0]\n    dim = tf.keras.backend.int_shape(z_mean)[1]\n    # by default, random_normal has mean=0 and std=1.0\n    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n    return z_mean + tf.keras.backend.exp(0.5 * z_log_var) * epsilon\n    \n    \ndef plot_results(models, data, batch_size=128, model_name=\"vae_mnist\"):\n    \"\"\"Plots labels and MNIST digits as function of 2-dim latent vector\n    # Arguments:\n        models (tuple): encoder and decoder models\n        data (tuple): test data and label\n        batch_size (int): prediction batch size\n        model_name (string): which model is using this function\n    \"\"\"\n\n    encoder, decoder = models\n    x_test, y_test = data\n    os.makedirs(model_name, exist_ok=True)\n\n    filename = os.path.join(model_name, \"vae_mean.png\")\n    # display a 2D plot of the digit classes in the latent space\n    z_mean, _, _ = encoder.predict(x_test,\n                                   batch_size=batch_size)\n    plt.figure(figsize=(12, 10))\n    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n    plt.colorbar()\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n    plt.savefig(filename)\n    plt.show()\n\n    filename = os.path.join(model_name, \"digits_over_latent.png\")\n    # display a 30x30 2D manifold of digits\n    n = 30\n    digit_size = 28\n    figure = np.zeros((digit_size * n, digit_size * n))\n    # linearly spaced coordinates corresponding to the 2D plot\n    # of digit classes in the latent space\n    grid_x = np.linspace(-4, 4, n)\n    grid_y = np.linspace(-4, 4, n)[::-1]\n\n    for i, yi in enumerate(grid_y):\n        for j, xi in enumerate(grid_x):\n            z_sample = np.array([[xi, yi]])\n            x_decoded = decoder.predict(z_sample)\n            digit = x_decoded[0].reshape(digit_size, digit_size)\n            figure[i * digit_size: (i + 1) * digit_size,\n                   j * digit_size: (j + 1) * digit_size] = digit\n\n    plt.figure(figsize=(10, 10))\n    start_range = digit_size // 2\n    end_range = n * digit_size + start_range + 1\n    pixel_range = np.arange(start_range, end_range, digit_size)\n    sample_range_x = np.round(grid_x, 1)\n    sample_range_y = np.round(grid_y, 1)\n    plt.xticks(pixel_range, sample_range_x)\n    plt.yticks(pixel_range, sample_range_y)\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n    plt.imshow(figure, cmap='Greys_r')\n    plt.savefig(filename)\n    plt.show()","metadata":{"_uuid":"7033562b28b56d02a768a92b0c7e2aa705f8daf8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = load_data('../input/mnist.npz')\n\nimage_size = x_train.shape[1]\noriginal_dim = image_size * image_size\nx_train = np.reshape(x_train, [-1, original_dim])\nx_test = np.reshape(x_test, [-1, original_dim])\nx_train = x_train.astype('float32') / 255\nx_test = x_test.astype('float32') / 255\n\n# network parameters\ninput_shape = (original_dim, )\nintermediate_dim = 512\nbatch_size = 128\nlatent_dim = 2\nepochs = 50\n\n# VAE model = encoder + decoder\n# build encoder model\ninputs = tf.keras.layers.Input(shape=input_shape, name='encoder_input')\nx = tf.keras.layers.Dense(intermediate_dim, activation='relu')(inputs)\nz_mean = tf.keras.layers.Dense(latent_dim, name='z_mean')(x)\nz_log_var = tf.keras.layers.Dense(latent_dim, name='z_log_var')(x)\n\n# use reparameterization trick to push the sampling out as input\nz = tf.keras.layers.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n\n# instantiate encoder model\nencoder = tf.keras.models.Model(inputs, [z_mean, z_log_var, z], name='encoder')\nencoder.summary()\n# tf.keras.utils.plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n\n# build decoder model\nlatent_inputs = tf.keras.layers.Input(shape=(latent_dim,), name='z_sampling')\nx = tf.keras.layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\noutputs = tf.keras.layers.Dense(original_dim, activation='sigmoid')(x)\n\n# instantiate decoder model\ndecoder = tf.keras.models.Model(latent_inputs, outputs, name='decoder')\ndecoder.summary()\n# tf.keras.utils.plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n\n# instantiate VAE model\noutputs = decoder(encoder(inputs)[2])\nvae = tf.keras.models.Model(inputs, outputs, name='vae_mlp')\n\nmodels = (encoder, decoder)\ndata = (x_test, y_test)\n# reconstruction_loss = tf.keras.losses.mse(inputs, outputs)\nreconstruction_loss = tf.keras.losses.binary_crossentropy(inputs, outputs)\n\nreconstruction_loss *= original_dim\n\nkl_loss = 1 + z_log_var - tf.keras.backend.square(z_mean) - tf.keras.backend.exp(z_log_var)\nkl_loss = tf.keras.backend.sum(kl_loss, axis=-1)\nkl_loss *= -0.5\nvae_loss = tf.keras.backend.mean(reconstruction_loss + kl_loss)\nvae.add_loss(vae_loss)\nvae.compile(optimizer='adam')\nvae.summary()\n# tf.keras.utils.plot_model(vae, to_file='vae_mlp.png', show_shapes=True)","metadata":{"_uuid":"40a1f16303af6139da25bd6083f02666d48adb42","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae.fit(x_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, None))\nvae.save_weights('vae_mlp.mnist.h5')","metadata":{"_kg_hide-output":true,"_uuid":"096400069244884bed9d5a7505bd2ff3dca6ad76","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Because the VAE is a generative model, we can also use it to generate new digits! Here we will scan the latent plane, sampling latent points at regular intervals and generating the corresponding digit for each of these points. This gives us a visualization of the latent manifold that \"generates\" the MNIST digits.\nplot_results(models, data, batch_size=batch_size, model_name='vae_mlp')","metadata":{"_uuid":"04890c9e5e5d7aa2c326f34d22aa5a7fd7b694c6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's it for Autoecoders. Generative Autoadverserial Networks work much better than Autoencoders. They also generalize really well over a large problem domain. Check out other kernels for some examples of GANs.","metadata":{"_uuid":"b19cf9d292188c2920d8d5e170b63e38f8ddf747"}}]}